{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#\n",
    "# Helper functions for data manipulation\n",
    "#\n",
    "################################################\n",
    "from PIL import Image\n",
    "import os, glob, re\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def ResizeWithProportions(im, desired_size):\n",
    "\t'''\n",
    "\tTake and image and resize it to a square of the desired size.\n",
    "\t0) If any dimension of the image is larger than the desired size, shrink until the image can fully fit in the desired size\n",
    "\t1) Add black paddings to create a square\n",
    "\t'''\n",
    "\n",
    "\told_size    = im.size\n",
    "\tlargest_dim = max(old_size)\n",
    "\tsmallest_dim = min(old_size)\n",
    "\n",
    "\t# If the image dimensions are very different, reducing the larger one to `desired_size` can make the other\n",
    "\t# dimension too small. We impose that it be at least 4 pixels.\n",
    "\tif desired_size*smallest_dim/largest_dim<4:\n",
    "\t\tprint('Image size: ({},{})'.format(largest_dim,smallest_dim ))\n",
    "\t\tprint('Desired size: ({},{})'.format(desired_size,desired_size))\n",
    "\t\traise ValueError('Images are too extreme rectangles to be reduced to this size. Try increasing the desired image size.')\n",
    "\n",
    "\trescaled    = 0 # This flag tells us whether there was a rescaling of the image (besides the padding). We can use it as feature for training.\n",
    "\n",
    "\t# 0) If any dimension of the image is larger than the desired size, shrink until the image can fully fit in the desired size\n",
    "\tif max(im.size)>desired_size:\n",
    "\n",
    "\t\tratio = float(desired_size)/max(old_size)\n",
    "\t\tnew_size = tuple([int(x*ratio) for x in old_size])\n",
    "\t\t# print('new_size:',new_size)\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tim = im.resize(new_size, Image.LANCZOS)\n",
    "\t\trescaled = 1\n",
    "\n",
    "    # 1) Add black paddings to create a square\n",
    "\tnew_im = Image.new(\"RGB\", (desired_size, desired_size), color=0)\n",
    "\tnew_im.paste(im, (\t(desired_size-im.size[0])//2,\n",
    "\t\t\t\t\t\t(desired_size-im.size[1])//2))\n",
    "\n",
    "\treturn new_im, rescaled\n",
    "\n",
    "def ReduceClasses(datapaths, class_select):\n",
    "\tprint('datapaths:',datapaths)\n",
    "\t# allClasses = [ name for name in os.listdir(datapaths) if os.path.isdir(os.path.join(datapaths, name)) ]\n",
    "\tallClasses = list(set([ name for idata in range(len(datapaths)) for name in os.listdir(datapaths[idata]) if os.path.isdir(os.path.join(datapaths[idata], name))]))\n",
    "\tprint('classes from datapaths:', allClasses)\n",
    "\tif class_select is None:\n",
    "\t\tclass_select = allClasses\n",
    "\telse:\n",
    "\t\tif not set(class_select).issubset(allClasses):\n",
    "\t\t\tprint('Some of the classes input by the user are not present in the dataset.')\n",
    "\t\t\tprint('class_select:',class_select)\n",
    "\t\t\tprint('all  classes:',allClasses)\n",
    "\t\t\traise ValueError\n",
    "\treturn class_select\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LoadMixed(datapaths, L, class_select=None, alsoImages=True, training_data=True):\n",
    "\t'''\n",
    "\tUses the data in datapath to create a DataFrame with images and features. \n",
    "\tFor each class, we read a tsv file with the features. This file also contains the name of the corresponding image, which we fetch and resize.\n",
    "\tFor each line in the tsv file, we then have all the features in the tsv, plus class name, image (as numpy array), and a binary variable stating whether the image was resized or not.\n",
    "\tAssumes a well-defined directory structure.\n",
    "\n",
    "\tArguments:\n",
    "\tdatapaths \t  - list with the paths where the data is stored. Inside each datapath, we expect to find directories with the names of the classes\n",
    "\tL \t\t\t  - images are rescaled to a square of size LxL (maintaining proportions)\n",
    "\tclass_select  - a list of the classes to load. If None (default), loads all classes \n",
    "\talsoImages    - flag that tells whether to only load features, or features+images\n",
    "\ttraining_data - flag for adding a subdirectory called training_data\n",
    "\tOutput:\n",
    "\tdf \t\t \t  - a dataframe with classname, npimage, rescaled, and all the columns contained in features.tsv\n",
    "\t'''\n",
    "\ttraining_data_dir = '/training_data/' if training_data==True else '/'\n",
    "\n",
    "\tdf = pd.DataFrame()\n",
    "\tclass_select=ReduceClasses(datapaths, class_select)\t# Decide whether to use all available classes\n",
    "\n",
    "\t# Loop for data loading\n",
    "\tfor c in class_select: # Loop over the classes\n",
    "\n",
    "\t\t# Read from tsv file, and create column with full path to the image\n",
    "\t\tdfFeat = pd.DataFrame()\n",
    "\t\tfor idp in range(len(datapaths)):\n",
    "\t\t\ttry: # It could happen that a class is contained in one datapath but not in the others\n",
    "\t\t\t\tdftemp = pd.read_csv(datapaths[idp]+c+'/features.tsv', sep = '\\t')\n",
    "\t\t\t\tdftemp['filename'] = [datapaths[idp]+c+training_data_dir+os.path.basename(dftemp.url[ii]) for ii in range(len(dftemp))]\n",
    "\t\t\t\tdfFeat = pd.concat([dfFeat, dftemp], axis=0, sort=True)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\tprint('class: {} ({})'.format(c, len(dfFeat)))\n",
    "\n",
    "\t\t\n",
    "\t\t# Each line in features.tsv should be associated with classname (and image, if the options say it's true)\n",
    "\t\tfor index, row in dfFeat.iterrows():\n",
    "\n",
    "\t\t\tif alsoImages:\n",
    "\t\t\t\timage=Image.open(row.filename)\n",
    "\t\t\t\timage,rescaled = ResizeWithProportions(image, L) # Set image's largest dimension to target size, and fill the rest with black pixels\n",
    "\t\t\t\tnpimage = np.array(image.copy() , dtype=np.float32)\t\t\t # Convert to numpy\n",
    "\n",
    "\t\t\t\tdftemp=pd.DataFrame([[c,npimage,rescaled]+row.to_list()], columns=['classname','npimage','rescaled']+dfFeat.columns.to_list())\n",
    "\t\t\t\timage.close()\n",
    "\t\t\telse: #alsoImages is False here\n",
    "\t\t\t\tdftemp=pd.DataFrame([[c]+row.to_list()] ,columns=['classname']+dfFeat.columns.to_list())\n",
    "\n",
    "\t\t\tdf=pd.concat([df,dftemp], axis=0, sort=True)\n",
    "\n",
    "\t# If images were loaded, scale the raw pixel intensities to the range [0, 1]\n",
    "\tif alsoImages:\n",
    "\t\tdf.npimage = df.npimage / 255.0 \n",
    "\n",
    "\treturn df.reset_index(drop=True) # The data was loaded without an index, that we add with reset_index()\n",
    "\n",
    "\n",
    "\n",
    "def LoadImage(filename, L=None, show=False):\n",
    "\t''' Loads one image, and rescales it to size L.\n",
    "\tThe pixel values are between 0 and 255, instead of between 0 and 1, so they should be normalized outside of the function \n",
    "\t'''\n",
    "\n",
    "\timage = Image.open(filename)\n",
    "\t# Set image's largest dimension to target size, and fill the rest with black pixels\n",
    "\tif L is None:\n",
    "\t\trescaled=0\n",
    "\telse:\n",
    "\t\timage,rescaled = ResizeWithProportions(image, L) # width and height are assumed to be the same (assertion at the beginning)\n",
    "\tnpimage = np.array(image.copy(), dtype=np.float32)\n",
    "\n",
    "\tif show:\n",
    "\t\timage.show()\n",
    "\timage.close()\n",
    "\treturn npimage, rescaled\n",
    "\n",
    "\n",
    "def LoadImages(datapaths, L, class_select=None, training_data=True):\n",
    "\t'''\n",
    "\tUses the data in datapath to create a DataFrame with images only. \n",
    "\tThis cannot be a particular case of the mixed loading, because the mixed depends on the files written in the features.tsv file, whereas here we fetch the images directly.\n",
    "\n",
    "\tArguments:\n",
    "\tdatapath \t - the path where the data is stored. Inside datapath, we expect to find directories with the names of the classes\n",
    "\tL \t\t\t - images are rescaled to a square of size LxL (maintaining proportions)\n",
    "\tclass_select - a list of the classes to load. If None (default), loads all classes \n",
    "\ttraining_data- a boolean variable to decide the structure of the directories\n",
    "\tOutput:\n",
    "\tdf \t\t\t - a dataframe with classname, npimage, rescaled.\n",
    "\t'''\n",
    "\n",
    "\tdf = pd.DataFrame()\n",
    "\tclass_select=ReduceClasses(datapaths, class_select)\t# Decide whether to use all available classes\n",
    "\n",
    "\t# The following condition is because the taxonomists used different directory structures\n",
    "\tnames='/training_data/*.jp*g' if training_data==True else '/*.jp*g'\n",
    "\n",
    "\n",
    "\tfor c in class_select:\n",
    "\n",
    "\t\t# Get names of images belonging to this class, from all the data paths\n",
    "\t\tclassImages = []\n",
    "\t\tfor idp in range(len(datapaths)):\n",
    "\t\t\tclassImages.extend( glob.glob(datapaths[idp]+'/'+c+'/'+names) )\n",
    "\n",
    "\t\t# Create an empty dataframe for this class\n",
    "\t\tdfClass=pd.DataFrame(columns=['classname','npimage'])\n",
    "\n",
    "\t\tprint('class: {} ({})'.format(c, len(classImages)))\n",
    "\n",
    "\t\tfor i,imageName in enumerate(classImages):\n",
    "\n",
    "\t\t\tnpimage,rescaled=LoadImage(imageName,L)\n",
    "\t\t\tdfClass.loc[i] = [c,npimage]\n",
    "\n",
    "\t\tdf=pd.concat([df,dfClass], axis=0)\n",
    "\n",
    "\tdf.npimage = df.npimage / 255.0 \n",
    "\n",
    "\treturn df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def LoadImageList(im_names, L, show=False):\n",
    "\t''' \n",
    "\tFunction that loads a list of images given in im_names, and returns \n",
    "\tthem in a numpy format that can be used by the classifier.\n",
    "\t'''\n",
    "\tnpimages=np.ndarray((len(im_names),L,L,3))\n",
    "\n",
    "\tfor i,im_name in enumerate(im_names):\n",
    "\t\tnpimage,rescaled=LoadImage(im_name,L, show)\n",
    "\t\tnpimages[i]=npimage\n",
    "\tnpimages/=255.0\n",
    "\treturn npimages\n",
    "\n",
    "\n",
    "class Cdata:\n",
    "\n",
    "\tdef __init__(self, datapath, L=None, class_select=None, kind='mixed', training_data=True):\n",
    "\t\tself.datapath=datapath\n",
    "\t\tif L is None and kind!='feat':\n",
    "\t\t\tprint('CData: image size needs to be set, unless kind is \\'feat\\'')\n",
    "\t\t\traise ValueError\n",
    "\t\tself.L=L\n",
    "\t\tself.class_select=class_select\n",
    "\t\tself.kind=kind\n",
    "\t\tself.df=None\n",
    "\t\tself.y=None\n",
    "\t\tself.X=None\n",
    "\t\tself.Load(self.datapath, self.L, self.class_select, self.kind, training_data=training_data)\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "\tdef Load(self, datapaths, L, class_select, kind='mixed', training_data=True):\n",
    "\t\t''' \n",
    "\t\tLoads dataset \n",
    "\t\tFor the moment, only mixed data. Later, also pure images or pure features.\n",
    "\t\t'''\n",
    "\t\tself.L=L\n",
    "\t\tself.datapath=datapaths\n",
    "\t\tself.class_select=class_select\n",
    "\t\tself.kind=kind\n",
    "\n",
    "\t\tif kind=='mixed':\n",
    "\t\t\tself.df = LoadMixed(datapaths, L, class_select, alsoImages=True)\n",
    "\t\telif kind=='feat':\n",
    "\t\t\tself.df = LoadMixed(datapaths, L, class_select, alsoImages=False)\n",
    "\t\telif kind=='image':\n",
    "\t\t\tself.df = LoadImages(datapaths, L, class_select, training_data=training_data)\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError('Only mixed, image or feat data-loading')\n",
    "\n",
    "\t\tself.classes=self.df['classname'].unique()\n",
    "\t\tself.kind=kind \t\t# Now the data kind is kind. In most cases, we had already kind=self.kind, but if the user tested another kind, it must be changed\n",
    "\t\tself.Check()  \t\t# Some sanity checks on the dataset\n",
    "\t\tself.CreateXy()\t\t# Creates X and y, i.e. features and labels\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "\tdef Check(self):\n",
    "\t\t''' Basic checks on the dataset '''\n",
    "\n",
    "\t\t#Number of different classes\n",
    "\t\tclasses=self.classes\n",
    "\t\tif len(classes)<2:\n",
    "\t\t\tprint('There are less than 2 classes ({})'.format(len(classes)))\n",
    "\t\t\traise ValueError\n",
    "\n",
    "\t\t# Columns potentially useful for classification\n",
    "\t\tucols=self.df.drop(columns=['classname','url','filename','file_size','timestamp'], errors='ignore').columns\n",
    "\t\tif len(ucols)<1:\n",
    "\t\t\tprint('Columns: {}'.format(self.df.columns))\n",
    "\t\t\traise ValueError('The dataset has no useful columns.')\n",
    "\n",
    "\t\t# Check for NaNs\n",
    "\t\tif self.df.isnull().any().any():\n",
    "\t\t\tprint('There are NaN values in the data.')\n",
    "\t\t\tprint(self.df)\n",
    "\t\t\traise ValueError\n",
    "\n",
    "\t\t# Check that the images have the expected size\n",
    "\t\tif 'npimage' in self.df.columns:\n",
    "\t\t\tif self.df.npimage[0].shape != (self.L, self.L, 3):\n",
    "\t\t\t\tprint('Cdata Check(): Images were not reshaped correctly: {} instead of {}'.format(self.npimage[0].shape, (self.L, self.L, 3)))\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\tdef CreateXy(self):\n",
    "\t\t''' \n",
    "\t\tCreates features and target\n",
    "\t\t- removing the evidently junk columns.\n",
    "\t\t- allowing to access images and features separately and confortably\n",
    "\t\t'''\n",
    "\n",
    "\t\tself.y = self.df.classname\n",
    "\t\tself.X = self.df.drop(columns=['classname','url','filename','file_size','timestamp'], errors='ignore')\n",
    "\n",
    "\t\tself.Ximage = self.X.npimage if (self.kind != 'feat') else None\n",
    "\t\tself.Xfeat  = self.X.drop(columns=['npimage'], errors='ignore') if (self.kind != 'image') else None\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "def ReadArgsTxt(modelpath, verbose=False):\n",
    "\t'''\n",
    "\tLooks with what arguments the model was trained, and makes a series of consistency checks.\n",
    "\tReads the following two files:\n",
    "\t- params.txt  (txt file with the simulation parameters -- parameter names are reconstructed through regex)\n",
    "\t- classes.npy (numpy file with the list of classes)\n",
    "\n",
    "\t'''\n",
    "\n",
    "\tprint('NOTIMPLEMENTED WARNING: ReadArgsTxt only reads some of the input parameters (those that were useful when I wrote the function, which may have changed)')\n",
    "\n",
    "\targsname=modelpath+'/params.txt'\n",
    "\tparams={'L':None,\n",
    "\t\t\t'model':None,\n",
    "\t\t\t'layers':[None,None],\n",
    "\t\t\t'datapaths':None,\n",
    "\t\t\t'outpath':None,\n",
    "\t\t\t'datakind':None,\n",
    "\t\t\t'ttkind':None\n",
    "\t\t\t}\n",
    "\n",
    "\t# Read Arguments\n",
    "\twith open(argsname,'r') as fargs:\n",
    "\t\targs=fargs.read()\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('---------- Arguments for generation of the model ----------')\n",
    "\t\t\tprint('{} contains the following parameters:\\n{}'.format(argsname,args))\n",
    "\t\t\tprint('-----------------------------------------------------------')\n",
    "\t\tfor s in re.split('[\\,,\\),\\(]',args):\n",
    "\t\t\tif 'L=' in s:\n",
    "\t\t\t\tparams['L']=np.int64(re.search('(\\d+)',s).group(1))\n",
    "\t\t\tif 'model=' in s:\n",
    "\t\t\t\tparams['model']=re.search('=\\'(.+)\\'$',s).group(1)\n",
    "\t\t\tif 'layers=' in s: #first layer\n",
    "\t\t\t\tparams['layers'][0]=np.int64(re.search('=\\[(.+)$',s).group(1))\n",
    "\t\t\tif re.match('^ \\d+',s): #second layer\n",
    "\t\t\t\tparams['layers'][1]=np.int64(re.match('^ (\\d+)',s).group(1))\n",
    "\t\t\tif 'datapaths=' in s:\n",
    "\t\t\t\t# print('datapaths: ',s)\n",
    "\t\t\t\ttemp = re.search('=\\[\\'(.+)\\'$',s).group(1)\n",
    "\t\t\t\tparams['datapaths']= [temp]\n",
    "\t\t\t\t# print('params[datapaths]=',params['datapaths'])\n",
    "\t\t\tif 'outpath=' in s:\n",
    "\t\t\t\tparams['outpath']=re.search('=\\'(.+)\\'$',s).group(1)\n",
    "\t\t\tif 'datakind=' in s:\n",
    "\t\t\t\tparams['datakind']=re.search('=\\'(.+)\\'$',s).group(1)\n",
    "\t\t\tif 'ttkind=' in s:\n",
    "\t\t\t\tparams['ttkind']=re.search('=\\'(.+)\\'$',s).group(1)\n",
    "\t\t\tif 'class_select=' in s:\n",
    "\t\t\t\tprint('class_select: ',s)\n",
    "\t\t\t\ttemp = re.search('=\\[\\'(.+)\\'\\]$',s).group(1)\n",
    "\t\t\t\tprint('temp:',temp)\n",
    "\t\t\t\tparams['class_select']= [temp]\n",
    "\t\t\t\tprint('params[class_select]=',params['class_select'])\n",
    "\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('We retrieve this subset of parameters:\\n',params)\n",
    "\t\t\tprint('-----------------------------------------------------------')\n",
    "\n",
    "\tdef OutputClassPaths():\n",
    "\t\t''' Auxiliary function for error messages '''\n",
    "\t\tprint('\\nclasses1 are the subdirectories in the following folders: ', datapaths)\n",
    "\t\tprint('classes1:',classes1)\n",
    "\t\tprint('\\nclasses2 full filename: ',modelpath+'classes2.npy')\n",
    "\t\tprint('classes2:',classes2)\n",
    "\t\tprint('')\n",
    "\n",
    "\n",
    "\t# Now we extract the classes. Typically, they should be written in the classes.npy file. \n",
    "\t# Since sometimes we reduce the number of classes, these might be fewer than those contained in the dataset.\n",
    "\n",
    "\n",
    "\t# Extract classes from npy file in output directory\n",
    "\ttry:\n",
    "\t\tclasses=np.load(modelpath+'/classes.npy',allow_pickle=True)\n",
    "\texcept FileNotFoundError:\n",
    "\t\t# If the classes.npy file does not exist, we just assume that all the classes were used\n",
    "\t\tprint('INPUT WARNING: the file {} was not found, so we assume that the classes are all those contained in {}'.format(modelpath+'/classes.npy',params['datapaths']))\n",
    "\t\tclasses=list(set([ name for idata in range(len(params['datapaths'])) for name in os.listdir(params['datapaths'][idata]) if os.path.isdir(os.path.join(params['datapaths'][idata], name))]))\t\t\n",
    "\n",
    "\tprint(classes)\n",
    "\n",
    "\treturn params, classes\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "\tpass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
