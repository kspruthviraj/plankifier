{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:258: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:552: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:553: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:258: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:552: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:553: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:258: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:552: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:553: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<ipython-input-1-bbb0727247d2>:258: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self.modelkind!='feat', self.modelkind!='mixed', \"We only augment with image data\")\n",
      "<ipython-input-1-bbb0727247d2>:552: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(input_shape[0]) == 3, \"MixedModel: first dimension should be images, but has shape {}\".format(input_shape[0]))\n",
      "<ipython-input-1-bbb0727247d2>:553: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(input_shape[1]) == 1, \"MixedModel: second dimension should be features, but has shape {}\".format(input_shape[1]))\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "from keras import metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Added by SK for MobileNet\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "def CreateParams(layers= None, lr =None, bs=None, optimizer=None, totEpochs= None, dropout=None, callbacks= None, \n",
    "\t\t\t\t initial_epoch=0, aug=None, modelfile=None, model_feat=None, model_image=None, load_weights=None, \n",
    "\t\t\t\t # override_lr=False, \n",
    "\t\t\t\t train=True, \n",
    "\t\t\t\t # numclasses=None\n",
    "\t\t\t\t ):\n",
    "\t''' Creates an empty dictionary with all possible entries'''\n",
    "\n",
    "\tparams={\n",
    "\t\t'layers': layers,\n",
    "        'lr': lr,\n",
    "        'bs': bs,\n",
    "        'optimizer': optimizer,\n",
    "        'totEpochs': totEpochs,\n",
    "        'dropout': dropout,\n",
    "        'callbacks': callbacks,\n",
    "        'initial_epoch': initial_epoch,\n",
    "        'aug': aug,\n",
    "        'modelfile': modelfile, # Name of the file where a model is stored, that we want to load\n",
    "        'model_feat': model_feat, # For mixed models, what the feature branch gets\n",
    "        'model_image': model_image, # For mixed models, what the image branch gets\n",
    "\t\t'load_weights': load_weights, # If you want to load weights from file, put the filename (with path) here\n",
    "\t\t# 'override_lr': override_lr, # Whether to load model from file\n",
    "\t\t'train': train, # Whether to train the model (e.g. maybe you only want to load it)\n",
    "\t\t# 'numclasses': numclasses, # If no labels are given, we must give the number of classes through this variable\n",
    "\t\t}\n",
    "\n",
    "\treturn params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CModelWrapper:\n",
    "\t'''\n",
    "\tA wrapper class for models\n",
    "\t'''\n",
    "\tdef __init__(self, trainX, trainY, testX, testY, params, verbose=False, numclasses=None):\n",
    "\n",
    "\t\tself.history, self.model = None, None\n",
    "\n",
    "\t\t(self.trainX, self.trainY, self.testX, self.testY, self.params, self.verbose) = (trainX, trainY, testX, testY, params, verbose)\n",
    "\n",
    "\t\tself.numclasses = numclasses\n",
    "\t\tif trainY is not None:\n",
    "\t\t\tassert(len(trainY[0]) == self.numclasses)\n",
    "\n",
    "\t\tself.SetArchitecture()   # Defines self.model\n",
    "\t\tself.InitModelWeights()\n",
    "\n",
    "\t\tif params['train'] == False: # If we are not interested in training, we are only loading the model\n",
    "\t\t\treturn\n",
    "\n",
    "\t\tself.SetOptimizer()\n",
    "\t\tself.Compile()\n",
    "\t\tself.Train() # Trains if params['train'] is set to True\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "\tdef InferModelKind(self):\n",
    "\t\t''' \n",
    "\t\tDecide whether the model in the wrapper is image, feat, or mixed.\n",
    "\t\tSets the following variables:\n",
    "\n",
    "\t\tmodelkind: tells us which kind of model we have (feat, image or mixed)\n",
    "\t\tmodelname: tells us which specific models we are useing (e.g. MLP, smallvgg, etc...)\n",
    "\n",
    "\t\t'''\n",
    "\n",
    "\t\tif (self.params['model_feat'] is None) and (self.params['model_image'] is None):\n",
    "\t\t\tprint('Either model_feat ({}) or model_image ({}) should be defined'.format(self.params['model_feat'],self.params['model_image']))\n",
    "\t\t\tself.modelkind = None\n",
    "\t\t\traise ValueError\n",
    "\n",
    "\t\telif self.params['model_image'] is None:\n",
    "\t\t\tself.modelkind = 'feat'\n",
    "\t\t\tself.modelname = self.params['model_feat']\n",
    "\t\t\tassert(len(np.shape(self.trainX[0])) == 1)\n",
    "\n",
    "\t\telif self.params['model_feat'] is None:\n",
    "\t\t\tself.modelkind = 'image'\n",
    "\t\t\tself.modelname = self.params['model_image']\n",
    "\t\t\tassert(len(np.shape(self.trainX[0])) == 3)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tself.modelkind = 'mixed'\n",
    "\t\t\tself.modelname = (self.params['model_image'], self.params['model_feat'])\n",
    "\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint('InferModelKind(): setting model kind to {}'.format(self.modelkind))\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\tdef SetModel(self):\n",
    "\n",
    "\t\tif self.modelkind == 'feat':\n",
    "\t\t\tself.SetModelFeat()\n",
    "\n",
    "\t\telif self.modelkind == 'image':\n",
    "\t\t\tself.SetModelImage()\n",
    "\n",
    "\t\telif self.modelkind == 'mixed':\n",
    "\t\t\tself.SetModelMixed()\n",
    "\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('SetModel: unrecognized modelkind {}'.format(self.modelkind))\n",
    "\n",
    "\tdef SetModelImage(self):\n",
    "\t\t'''\n",
    "\t\tCurrently available image models: MLP, conv2, smallvgg,mobilenet\n",
    "\t\t'''\n",
    "\n",
    "\t\tif self.modelname == 'mlp':\n",
    "\t\t\tself.model = MultiLayerPerceptron.Build2Layer(input_shape=self.trainX[0].shape, classes=self.numclasses, layers=self.params['layers'])\n",
    "\t\telif self.modelname == 'conv2':\n",
    "\t\t\tself.model = Conv2Layer.Build(input_shape=self.trainX[0].shape, classes=self.numclasses, last_activation='softmax')\n",
    "\t\telif self.modelname == 'mobile':\n",
    "\t\t\tself.model = MobileNetPK.Build(input_shape=self.trainX[0].shape, classes=self.numclasses)          \n",
    "\t\telif self.modelname == 'smallvgg':\n",
    "\t\t\tself.model = SmallVGGNet.Build(input_shape=self.trainX[0].shape, classes=self.numclasses)\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError('SetModelImage() - chosen model {} is not implemented'.format(self.modelname))\n",
    "\n",
    "\tdef SetModelFeat(self):\n",
    "\t\t'''\n",
    "\t\tCurrently available feature models: MLP\n",
    "\t\t'''\n",
    "\n",
    "\t\tif self.modelname == 'mlp':\n",
    "\t\t\tself.model = MultiLayerPerceptron.Build2Layer(input_shape=self.trainX[0].shape, classes=self.numclasses, layers=self.params['layers'])\n",
    "\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError('SetModelImage() - chosen model {} is not implemented'.format(self.modelname))\n",
    "\n",
    "\tdef SetModelMixed(self):\n",
    "\t\t'''\n",
    "\t\tSet Model for image+features input data\n",
    "\t\t'''\n",
    "\n",
    "\t\tshape_of_image = self.trainX[0][0].shape\n",
    "\t\tshape_of_feat  = self.trainX[1][0].shape\n",
    "\n",
    "\t\t# Currently there is only one option for mixed models, so no branching required\n",
    "\t\tself.model = MixedModel.Build(\tinput_shape\t= [shape_of_image, shape_of_feat], \n",
    "\t\t\t\t\t\t\t\t\t\tclasses \t= self.numclasses,\n",
    "\t\t\t\t\t\t\t\t\t\tmodelnames\t= self.modelname, # This is a tuple with 2 model names, one per branch\n",
    "\t\t\t\t\t\t\t\t\t\tlayers\t\t= [self.params['layers'], self.params['layers']] # For the moment we're assigning the same layers to each mlp. These layers are only used if the models are MLP\n",
    "\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "\n",
    "\tdef SetArchitecture(self):\n",
    "\t\t'''\n",
    "\t\tSet Model Architecture in the self.model attribute\n",
    "\t\t'''\n",
    "\n",
    "\t\t# Either load the model...\n",
    "\t\tif self.params['modelfile'] is not None:\n",
    "\t\t\tself.model=keras.models.load_model(self.params['modelfile'])\n",
    "\t\t\tself.modelkind = 'undetermined' # At some point we should infer the model kind from the loaded architecture\n",
    "\n",
    "\t\t\t'''\n",
    "\t\t\tWe can decide to override the features of the loaded model. In the following example,\n",
    "\t\t\tI do it for the learning rate. This is commented out because I am not using it, and because \n",
    "\t\t\tprobably it should be done in a specific method devoted to the learning rate (which will be\n",
    "\t\t\tlikely developed when the LR schedule is implemented)\n",
    "\n",
    "\t\t\tprint('LR of the loaded model:', K.get_value(model.optimizer.lr))\n",
    "\t\t\tif params['override_lr']==True:\n",
    "\t\t\t\tK.set_value(model.optimizer.lr, params['lr'])\n",
    "\t\t\t\tprint('Setting the LR to', params['lr'])\n",
    "\n",
    "\n",
    "\t\t\tCurrently, we are overriding the optimizer state and compilation. \n",
    "\t\t\tWe likely want to change this.\n",
    "\t\t\t'''\n",
    "\t\t\n",
    "\t\t# ...or start a model from scratch\n",
    "\t\telse:\n",
    "\t\t\tself.InferModelKind()\n",
    "\t\t\tself.SetModel()\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "\tdef InitModelWeights(self):\n",
    "\t\t'''\n",
    "\t\tWeight initialization. This function is only partly implemented, since custom initializations are not done.\n",
    "\t\t'''\n",
    "\n",
    "\t\tif (self.params['load_weights'] is None):\n",
    "\t\t\tprint('WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change in order to have better control.')\n",
    "\t\telse:\n",
    "\t\t\tprint('Loading weights from ',self.params['load_weights'])\n",
    "\t\t\tself.model.load_weights(self.params['load_weights'])\n",
    "\n",
    "\n",
    "\tdef SetOptimizer(self):\n",
    "\n",
    "\t\t# Set Optimizer\n",
    "\t\tif self.params['optimizer'] == 'sgd':\n",
    "\t\t\tself.optimizer = keras.optimizers.SGD(lr=self.params['lr'], nesterov=True)\n",
    "\n",
    "\t\telif self.params['optimizer'] == 'adam':\n",
    "\t\t\tself.optimizer = keras.optimizers.Adam(learning_rate=self.params['lr'], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "\tdef Compile(self):\n",
    "\n",
    "\t\tself.model.compile(loss=\"categorical_crossentropy\", optimizer=self.optimizer, metrics=[\"accuracy\"])\n",
    "\t\t\n",
    "\t\treturn\t\t\t\n",
    "\n",
    "\n",
    "\tdef Train(self):\n",
    "\t\t'''\n",
    "\t\tTrains the model if params['train'] is set to True, and logs the history in self.history\n",
    "\t\t'''\n",
    "\n",
    "\n",
    "\t\tif self.params['train']:\n",
    "\n",
    "\t\t\tif self.params['aug'] is None:\n",
    "\n",
    "\t\t\t\tself.history = self.model.fit(\n",
    "\t\t\t\t\t\t\t\t\tself.trainX, self.trainY, \n",
    "\t\t\t\t\t\t\t\t\tvalidation_data=(self.testX, self.testY), \n",
    "\t\t\t\t\t\t\t\t\tepochs=self.params['totEpochs'], \n",
    "\t\t\t\t\t\t\t\t\tbatch_size=self.params['bs'], \n",
    "\t\t\t\t\t\t\t\t\tcallbacks=self.params['callbacks'],\n",
    "\t\t\t\t\t\t\t\t\tinitial_epoch = self.params['initial_epoch'])\n",
    "\t\t\telse:\n",
    "\t\t\t\tassert(self.modelkind!='feat', self.modelkind!='mixed', \"We only augment with image data\")\n",
    "\t\t\t\tself.history = self.model.fit(\n",
    "\t\t\t\t\t\t\t\t\tself.params['aug'].flow(self.trainX, self.trainY, batch_size=self.params['bs']), \n",
    "\t\t\t\t\t\t\t\t\tvalidation_data=(self.testX, self.testY), \n",
    "\t\t\t\t\t\t\t\t\tepochs=self.params['totEpochs'], \n",
    "\t\t\t\t\t\t\t\t\tcallbacks=self.params['callbacks'],\n",
    "\t\t\t\t\t\t\t\t\tinitial_epoch = self.params['initial_epoch'],\n",
    "\t\t\t\t\t\t\t\t\tsteps_per_epoch=len(self.trainX)//self.params['bs']\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "# def PlainModel(trainX, trainY, testX, testY, params):\n",
    "# \t'''\n",
    "# \tA wrapper for models that use feature-only or image-only data\n",
    "# \t'''\n",
    "\n",
    "# \tnumclasses = len(trainY[0]) if (params['numclasses'] is None) else params['numclasses']\n",
    "\n",
    "# \t#\n",
    "# \t# Define model architecture\n",
    "# \t#\n",
    "# \tif params['model'] is None:\n",
    "\n",
    "# \t\t# See whether input is images or features\n",
    "# \t\tif len(np.shape(trainX[0]))==3:\n",
    "# \t\t\tmodelkind = params['model_image']\n",
    "# \t\telif len(np.shape(trainX[0]))==1:\n",
    "# \t\t\tmodelkind = params['model_feat']\n",
    "# \t\telse:\n",
    "# \t\t\traise RuntimeError('PlainModel(): The shape of the input is neither 1D (feat) nor 3D (image)')\n",
    "\n",
    "\n",
    "# \t\t# Define model\n",
    "# \t\tif modelkind == 'mlp':\n",
    "# \t\t\tmodel = MultiLayerPerceptron.Build2Layer(input_shape=trainX[0].shape, classes=numclasses, layers=params['layers'])\n",
    "# \t\telif modelkind == 'conv2':\n",
    "# \t\t\tmodel = Conv2Layer.Build(input_shape=trainX[0].shape, classes=numclasses, last_activation='softmax')\n",
    "# \t\telif modelkind == 'smallvgg':\n",
    "# \t\t\tmodel = SmallVGGNet.Build(input_shape=trainX[0].shape, classes=numclasses)\n",
    "# \t\telse:\n",
    "# \t\t\traise NotImplementedError('PlainModel() - chosen model is not implemented')\n",
    "\n",
    "# \t\t# Initialize weights\n",
    "# \t\tif params['load_weights'] is None:\n",
    "# \t\t\tprint('WARNING: At the current state, we are taking the default weight initialization, whatever it is. This must change.')\n",
    "# \t\telse:\n",
    "# \t\t\tprint('Loading weights from ',params['load_weights'])\n",
    "# \t\t\tmodel.load_weights(params['load_weights'])\n",
    "\t\t\n",
    "# \t\t# Set Optimizer\n",
    "# \t\tif params['optimizer'] == 'sgd':\n",
    "# \t\t\toptimizer=keras.optimizers.SGD(lr=params['lr'], nesterov=True)\n",
    "# \t\telif params['optimizer'] == 'adam':\n",
    "# \t\t\toptimizer = keras.optimizers.Adam(learning_rate=params['lr'], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# \t\tmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# \telse:\n",
    "# \t\tmodel = params['model']\n",
    "# \t\tif params['load_weights'] is not None:\n",
    "# \t\t\tmodel.load_weights(params['load_weights'])\n",
    "# \t\t# print('LR of the loaded model:', K.get_value(model.optimizer.lr))\n",
    "# \t\t# if params['override_lr']==True:\n",
    "# \t\t# \tK.set_value(model.optimizer.lr, params['lr'])\n",
    "# \t\t# \tprint('Setting the LR to', params['lr'])\n",
    "\n",
    "# \tif params['train']:\n",
    "\n",
    "# \t\tif params['aug'] is None:\n",
    "\n",
    "# \t\t\thistory = model.fit(\n",
    "# \t\t\t\t\t\t\t\ttrainX, trainY, \n",
    "# \t\t\t\t\t\t\t\tvalidation_data=(testX, testY), \n",
    "# \t\t\t\t\t\t\t\tepochs=params['totEpochs'], \n",
    "# \t\t\t\t\t\t\t\tbatch_size=params['bs'], \n",
    "# \t\t\t\t\t\t\t\tcallbacks=params['callbacks'],\n",
    "# \t\t\t\t\t\t\t\tinitial_epoch = params['initial_epoch'])\n",
    "# \t\telse:\n",
    "# \t\t\thistory = model.fit_generator(\n",
    "# \t\t\t\t\t\t\t\tparams['aug'].flow(trainX, trainY, batch_size=params['bs']), \n",
    "# \t\t\t\t\t\t\t\tvalidation_data=(testX, testY), \n",
    "# \t\t\t\t\t\t\t\tepochs=params['totEpochs'], \n",
    "# \t\t\t\t\t\t\t\tcallbacks=params['callbacks'],\n",
    "# \t\t\t\t\t\t\t\tinitial_epoch = params['initial_epoch'],\n",
    "# \t\t\t\t\t\t\t\tsteps_per_epoch=len(trainX)//params['bs']\n",
    "# \t\t\t\t\t\t\t\t)\n",
    "\n",
    "# \telse: #params['train']==False here\n",
    "# \t\thistory=None\n",
    "\n",
    "# \treturn history, model\n",
    "\n",
    "\n",
    "\n",
    "def MixedModel(trainX, trainY, testX, testY, params):\n",
    "\t'''\n",
    "\tA wrapper for models that use mixed data\n",
    "\t'''\n",
    "\n",
    "\tnclasses=len(trainY[0])\n",
    "\n",
    "\t# We assume that trainX and testX are in the format: [images, features]\n",
    "\ttrainXi, trainXf = trainX[0], trainX[1]\n",
    "\ttestXi , testXf  =  testX[0],  testX[1]\n",
    "\tassert(len(trainXi.shape)>len(trainXf.shape))\n",
    "\tassert(len( testXi.shape)>len( testXf.shape))\n",
    "\n",
    "\t# Number of output nodes of the image and feature branches (will become a user parameter)\n",
    "\tnout_f = params['layers'][1]\n",
    "\tnout_i = params['layers'][1]\n",
    "\n",
    "\n",
    "\t## First branches - features and images separate\n",
    "\t# Set model for first branch on features\n",
    "\tif params['model_feat'] == 'mlp':\n",
    "\t\tmodel_feat = MultiLayerPerceptron.Build2Layer(\n",
    "\t\t\tinput_shape=trainXf[0].shape , classes=nout_f, last_activation = 'sigmoid', layers=params['layers'])\n",
    "\telse: \n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\t# Set model for first branch on images\n",
    "\tif params['model_image'] == 'mlp':\n",
    "\t\tmodel_image = MultiLayerPerceptron.Build2Layer(\n",
    "\t\t\tinput_shape=trainXi[0].shape, classes=nout_i, last_activation = 'sigmoid', layers=params['layers'])\n",
    "\telif params['model_image'] == 'conv2':\n",
    "\t\tmodel_image = Conv2Layer.Build(\n",
    "\t\t\tinput_shape=trainXi[0].shape, classes=nout_i, last_activation = 'sigmoid')\n",
    "\telif params['model_image'] == 'mobile':\n",
    "\t\tmodel_image = MobileNet.Build(\n",
    "\t\t\tinput_shape=trainXi[0].shape, classes=nout_i, last_activation = 'sigmoid')\n",
    "\telif params['model_image'] == 'smallvgg':\n",
    "\t\tmodel_image = SmallVGGNet.Build(\n",
    "\t\t\tinput_shape=trainXi[0].shape, classes=nout_i, last_activation = 'sigmoid')\n",
    "\telse: \t\t\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "\t## Second branch - join features and images\n",
    "\tcombinedInput = concatenate([model_image.output, model_feat.output]) # Combine the two\n",
    "\tmodel_join = Dense(64, activation=\"relu\")(combinedInput)\n",
    "\tmodel_join = Dense(nclasses, activation=\"softmax\")(model_join)\t\t\t\t\n",
    "\tmodel = Model(inputs=[model_image.input, model_feat.input], outputs=model_join)\n",
    "\n",
    "\tif params['optimizer'] == 'sgd':\n",
    "\t\toptimizer=keras.optimizers.SGD(lr=params['lr'], nesterov=True)\n",
    "\telif params['optimizer'] == 'adam':\n",
    "\t\toptimizer = keras.optimizers.Adam(learning_rate=params['lr'], beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\tmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "\tif params['aug'] is None:\n",
    "\t\n",
    "\t\thistory = model.fit(\n",
    "\t\t\t\t\t\t\t[trainXi,trainXf], trainY, \n",
    "\t\t\t\t\t\t\tvalidation_data=([testXi,testXf], testY), \n",
    "\t\t\t\t\t\t\tepochs=params['totEpochs'], \n",
    "\t\t\t\t\t\t\tbatch_size=params['bs'], \n",
    "\t\t\t\t\t\t\tcallbacks=params['callbacks'],\n",
    "\t\t\t\t\t\t\tinitial_epoch = params['initial_epoch']\n",
    "\t\t\t\t\t\t\t)\n",
    "\n",
    "\telse: #here, params['aug'] is set\n",
    "\n",
    "\t\thistory = model.fit_generator(\n",
    "\t\t\t\t\t\t\tparams['aug'].flow([trainXi,trainXf], trainY, batch_size=params['bs']), \n",
    "\t\t\t\t\t\t\tvalidation_data=([testXi,testXf], testY), \n",
    "\t\t\t\t\t\t\tepochs=params['totEpochs'], \n",
    "\t\t\t\t\t\t\tcallbacks=params['callbacks'],\n",
    "\t\t\t\t\t\t\tinitial_epoch = params['initial_epoch'],\n",
    "\t\t\t\t\t\t\tsteps_per_epoch=len(trainXi)//params['bs']\n",
    "\t\t\t\t\t\t\t)\n",
    "\n",
    "\treturn history, model\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "\t@staticmethod\n",
    "\tdef Build2Layer(input_shape, classes, layers=[64,32], activation=\"sigmoid\", last_activation=\"softmax\"):\n",
    "\t\tmodel = Sequential()\n",
    "\t\tif len(input_shape)==1:\n",
    "\t\t\tmodel.add(Dense(layers[0], input_shape=input_shape, activation=activation))\n",
    "\t\telse:\n",
    "\t\t\tmodel.add( Flatten(input_shape=input_shape ) )\n",
    "\t\t\tmodel.add(Dense(layers[0], activation=activation))\n",
    "\t\tmodel.add(Dense(layers[1], activation=activation))\n",
    "\n",
    "\t\tmodel.add(Dense(classes, activation=last_activation))\n",
    "\t\treturn model\n",
    "\n",
    "class Conv2Layer:\n",
    "\t@staticmethod\n",
    "\tdef Build(input_shape, classes, last_activation='softmax'):\n",
    "\t\tmodel = Sequential()\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# Beware, kernel_size is hard coded for the moment, so it might not work if images are small\n",
    "\t\tmodel.add(Conv2D(64, kernel_size=24, activation='relu', input_shape=input_shape))\n",
    "\t\tmodel.add(Conv2D(32, kernel_size=12, activation='relu'))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Flatten())\n",
    "\n",
    "\t\tmodel.add(Dense(classes, activation=last_activation))\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "class SmallVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef Build(input_shape, classes, last_activation='softmax'):\n",
    "\t\tmodel = Sequential()\n",
    "\t\tchanDim = -1 \t\t# initialize the model along with the input shape to be \"channels last\" and the channels dimension itself\n",
    "\n",
    "\t\t# CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# (CONV => RELU) * 2 => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# (CONV => RELU) * 3 => POOL layer set\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(last_activation))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "class MixedModel:\n",
    "\t@staticmethod\n",
    "\tdef Build(input_shape, classes, modelnames=['conv2','mlp'], nout=[32,32], ncombine=32, layers=[[128,64],[128,64]]):\n",
    "\t\t'''\n",
    "\t\tBuilds model that takes features on one side, and images on the other.\n",
    "\t\tSome things are hard-coded because I didn't really use mixed models for the moment.\n",
    "\n",
    "\t\tWe assume that mixed variables are in the format: [images, features]\n",
    "\n",
    "\t\tFeatures     Images\n",
    "\t\t\t|\t\t\t|\n",
    "\t\t\t|\t\t\t|\n",
    "\t\t\t\\          /\n",
    "\t\t\t \\        /\n",
    "\t\t\t  \\      /\n",
    "\t\t\t   \\    /\n",
    "\t\t\t\t\\  /\n",
    "\t\t\t\t \\/\n",
    "\t\t\t\t ||\n",
    "\t\t\t\t ||\n",
    "\t\t\t   Output\t\t\t   \n",
    "\n",
    "\t\tInput:\n",
    "\t\t- input_shape:\t[shape_of_feat, shape_of_image]\n",
    "\t\t- classes: \t\tnumber of classes\n",
    "\t\t- nout:\t\t\t[#output nodes of feature branch, #output nodes of image branch]\n",
    "\t\t- ncombine:\t\tsize of the hidden layer that combines the two branches\n",
    "\t\t- models:  \t\t[model of feature branch, model of image branch]\n",
    "\t\t- layers:  \t\t[model of feature branch, model of image branch]\n",
    "\n",
    "\t\tOutput: \n",
    "\t\t- a kickass model\n",
    "\t\t'''\n",
    "\n",
    "\t\t# Make sure that mixed variables are in the format: [images, features]\n",
    "\t\tassert(len(input_shape[0]) == 3, \"MixedModel: first dimension should be images, but has shape {}\".format(input_shape[0]))\n",
    "\t\tassert(len(input_shape[1]) == 1, \"MixedModel: second dimension should be features, but has shape {}\".format(input_shape[1]))\n",
    "\n",
    "\t\t#\n",
    "\t\t# Image branch\n",
    "\t\t#\n",
    "\t\tif modelnames[0] == 'mlp':\n",
    "\t\t\tmodel_image = MultiLayerPerceptron.Build2Layer(\n",
    "\t\t\t\tinput_shape=input_shape[0], classes=nout[0], last_activation = 'sigmoid', layers=layers[0])\n",
    "\t\telif modelnames[0] == 'conv2':\n",
    "\t\t\tmodel_image = Conv2Layer.Build(\n",
    "\t\t\t\tinput_shape=input_shape[0], classes=nout[0], last_activation = 'sigmoid')\n",
    "\t\telif modelnames[0] == 'smallvgg':\n",
    "\t\t\tmodel_image = SmallVGGNet.Build(\n",
    "\t\t\t\tinput_shape=input_shape[0], classes=nout[0], last_activation = 'sigmoid')\n",
    "\t\telse: \t\t\n",
    "\t\t\traise NotImplementedError('MixedModel -- Not implemented model image')\n",
    "\n",
    "\t\t#\n",
    "\t\t# Feature branch\n",
    "\t\t#\n",
    "\t\tif modelnames[1] == 'mlp':\n",
    "\t\t\tmodel_feat = MultiLayerPerceptron.Build2Layer(\n",
    "\t\t\t\tinput_shape=input_shape[1] , classes=nout[1], last_activation = 'sigmoid', layers=layers[1])\n",
    "\t\telse: \n",
    "\t\t\traise NotImplementedError('MixedModel -- Not implemented model feat')\n",
    "\n",
    "\n",
    "\t\t#\n",
    "\t\t# Combine branches\n",
    "\t\t#\n",
    "\t\tcombinedInput = concatenate([model_image.output, model_feat.output]) # Combine the two\n",
    "\t\tmodel_join = Dense(ncombine, activation=\"relu\")(combinedInput)\n",
    "\t\tmodel_join = Dense(classes, activation=\"softmax\")(model_join)\t\t\t\t\n",
    "\t\tmodel = Model(inputs=[model_image.input, model_feat.input], outputs=model_join)\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "class LeNet: # This is from old code - was not tested here\n",
    "\t@staticmethod\n",
    "\tdef Build(width, height, depth, classes):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\n",
    "\t\t# first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(20, (5, 5), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model\n",
    "    \n",
    "    \n",
    "    \n",
    "class MobileNetPK:\n",
    "\t@staticmethod\n",
    "\tdef Build(input_shape, classes):\n",
    "\t\t# initialize the model\n",
    "\t\tbase_model=MobileNet(input_shape=input_shape,weights='imagenet',include_top=False,input_tensor=Input(shape=(128, 128, 3))) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\t\t\n",
    "    # Add custom layers that needs to be trained\n",
    "\t\tshape = (int(1024), 1, 1)\n",
    "\t\tx=base_model.output\n",
    "\t\tx=GlobalAveragePooling2D()(x)\n",
    "\t\tx = Dropout(rate = 0.4, name='dropout1')(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\tx = Dense(512, activation='relu', bias_initializer='zeros')(x)\n",
    "\t\tx = Dropout(rate = 0.3, name='dropout2')(x)\n",
    "\t\tx = BatchNormalization()(x)  \n",
    "\t\tpreds = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n",
    "\t\tmodel=Model(inputs=base_model.input,outputs=preds) #now a model has been created based on our architecture\n",
    "\t\tfor layer in model.layers[-7:]:\n",
    "\t\t\tlayer.trainable = True\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
